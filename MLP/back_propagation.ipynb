{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementing back propagation from the scratch\n",
    "- Pytorch loss.backward() workings and comparing them to manual gradients created by this implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as Func\n",
    "import matplotlib.pyplot as plt  # for making figures\n",
    "import random\n",
    "import math\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Black code formatter (Optional)\n",
    "%load_ext lab_black"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['emma', 'olivia', 'ava', 'isabella', 'sophia', 'charlotte', 'mia', 'amelia']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read in all the words\n",
    "words = open(\"names.txt\", \"r\").read().splitlines()\n",
    "words[:8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32033"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: 'a', 2: 'b', 3: 'c', 4: 'd', 5: 'e', 6: 'f', 7: 'g', 8: 'h', 9: 'i', 10: 'j', 11: 'k', 12: 'l', 13: 'm', 14: 'n', 15: 'o', 16: 'p', 17: 'q', 18: 'r', 19: 's', 20: 't', 21: 'u', 22: 'v', 23: 'w', 24: 'x', 25: 'y', 26: 'z', 0: '.'}\n",
      "27\n"
     ]
    }
   ],
   "source": [
    "# build the vocabulary of characters and mappings to/from integers\n",
    "chars = sorted(list(set(\"\".join(words))))\n",
    "stoi = {s: i + 1 for i, s in enumerate(chars)}\n",
    "stoi[\".\"] = 0\n",
    "itos = {i: s for s, i in stoi.items()}\n",
    "vocab_size = len(itos)\n",
    "print(itos)\n",
    "print(vocab_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating the data set for the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build the dataset\n",
    "block_size = (\n",
    "    3  # context length: how many characters do we take to predict the next one?\n",
    ")\n",
    "\n",
    "\n",
    "def build_dataset(words):\n",
    "    \"\"\"\n",
    "    This builds the dataset and split it into the appropriate sets\n",
    "\n",
    "    Args:\n",
    "        - Words: A file containing all the names\n",
    "\n",
    "    Returns:\n",
    "        - X: A tensor containing the previous sequence of characters\n",
    "        - Y: A tensor containing the next character\n",
    "    \"\"\"\n",
    "    X, Y = [], []\n",
    "    for w in words:\n",
    "        # print(w)\n",
    "\n",
    "        context = [0] * block_size\n",
    "\n",
    "        for ch in w + \".\":\n",
    "            ix = stoi[ch]\n",
    "            X.append(\n",
    "                context\n",
    "            )  # append a list of block size 3 for the number of chars in a word\n",
    "            Y.append(ix)  # append the character number\n",
    "            context = context[1:] + [ix]  # crop and append\n",
    "\n",
    "    X = torch.tensor(X)\n",
    "    Y = torch.tensor(Y)\n",
    "    print(X.shape, Y.shape)\n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([182625, 3]) torch.Size([182625])\n",
      "torch.Size([22655, 3]) torch.Size([22655])\n",
      "torch.Size([22866, 3]) torch.Size([22866])\n"
     ]
    }
   ],
   "source": [
    "# Sampling from the dataset\n",
    "random.seed(42)\n",
    "random.shuffle(words)\n",
    "n1 = int(0.8 * len(words))\n",
    "n2 = int(0.9 * len(words))\n",
    "\n",
    "X_train, Y_train = build_dataset(words[:n1])\n",
    "X_dev, Y_dev = build_dataset(words[n1:n2])\n",
    "X_test, Y_test = build_dataset(words[n2:])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Boilerplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cmp(s, dt, t):\n",
    "    \"\"\"\n",
    "    An Utility function used for comparing manual gradients to PyTorch gradients\n",
    "\n",
    "    Args:\n",
    "        s:\n",
    "        dt:\n",
    "        t:\n",
    "\n",
    "    Returns:\n",
    "        A boolean value if they are exact or approximately close or not and the maximum \n",
    "        difference between them\n",
    "    \"\"\"\n",
    "    ex = torch.all(dt == t.grad).item()\n",
    "    app = torch.allclose(dt, t.grad)\n",
    "    maxdiff = (dt - t.grad).abs().max().item()\n",
    "    print(\n",
    "        f\"{s:15s} | exact: {str(ex):5s} | approximate: {str(app):5s} | maxdiff: {maxdiff}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12297\n"
     ]
    }
   ],
   "source": [
    "# Initialization\n",
    "n_embd = 10  # the dimensionality of the character embedding vectors\n",
    "n_hidden = 200  # the number of neurons in the hidden layer of the MLP\n",
    "\n",
    "gen = torch.Generator().manual_seed(2147483647)  # for reproducibility\n",
    "C = torch.randn((vocab_size, n_embd), generator=gen)\n",
    "\n",
    "# Layer 1\n",
    "W1 = torch.randn((n_embd * block_size, n_hidden), generator=gen) * (\n",
    "    (5 / 3) / math.sqrt(n_embd * block_size)\n",
    ")\n",
    "b1 = torch.randn(n_hidden, generator=gen) * 0.01\n",
    "\n",
    "# Layer 2\n",
    "W2 = torch.randn((n_hidden, vocab_size), generator=gen) * 0.1\n",
    "b2 = (\n",
    "    torch.randn(vocab_size, generator=gen) * 0.1\n",
    ")  # initialize b2 as a smaller value to remove the bias\n",
    "\n",
    "# batch normalization parameters\n",
    "bnGain = torch.randn((1, n_hidden)) * 0.1 + 1.0\n",
    "bnBias = torch.randn((1, n_hidden)) * 0.1\n",
    "\n",
    "# Most of the parameters are initialized in non-standard ways\n",
    "# because sometimes initializating with e.g. all zeros could mask an incorrect\n",
    "# implementation of the backward pass.\n",
    "parameters = [C, W1, b1, W2, b2, bnBias, bnGain]\n",
    "print(sum(p.nelement() for p in parameters))  # number of parameters in total\n",
    "for p in parameters:\n",
    "    p.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constructing the Minibatch\n",
    "batch_size = 32\n",
    "n = batch_size\n",
    "ix = torch.randint(0, X_train.shape[0], (batch_size,), generator=gen)\n",
    "X_batch, Y_batch = X_train[ix], Y_train[ix]  # batch X,Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(3.7524, grad_fn=<NegBackward0>)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Forward pass\n",
    "emb = C[X_batch]  # embed the characters into vectors\n",
    "embcat = emb.view(emb.shape[0], -1)  # concatenate the vectors\n",
    "\n",
    "## Linear layer\n",
    "hprebn = embcat @ W1 + b1  # hidden layer pre-activation\n",
    "\n",
    "# Batch Normalization layer\n",
    "# -------------------------------------------------------------\n",
    "bnMeani = 1 / n * hprebn.sum(0, keepdim=True)\n",
    "bnDiff = hprebn - bnMeani\n",
    "bnDiff2 = bnDiff**2\n",
    "bnVar = (\n",
    "    1 / (n - 1) * (bnDiff2).sum(0, keepdim=True)\n",
    ")  # note: Bessel's correction (dividing by n-1, not n)\n",
    "bnVar_inv = (bnVar + 1e-5) ** -0.5\n",
    "bnraw = bnDiff * bnVar_inv\n",
    "hpreact = bnGain * bnraw + bnBias\n",
    "# -------------------------------------------------------------\n",
    "\n",
    "## Non-linearity\n",
    "h = torch.tanh(hpreact)  # hidden layer\n",
    "\n",
    "# Linear layer 2\n",
    "logits = h @ W2 + b2  # output layer\n",
    "\n",
    "# Cross entropy Loss function\n",
    "logit_maxes = logits.max(1, keepdim=True).values\n",
    "norm_logits = logits - logit_maxes  # subtract max for numerical stability\n",
    "counts = norm_logits.exp()\n",
    "counts_sum = counts.sum(1, keepdims=True)\n",
    "counts_sum_inv = (\n",
    "    counts_sum**-1\n",
    ")  # if I use (1.0 / counts_sum) instead then I can't get backprop to be bit exact...\n",
    "probs = counts * counts_sum_inv\n",
    "logprobs = probs.log()\n",
    "loss = -logprobs[range(n), Y_batch].mean()\n",
    "\n",
    "\n",
    "# PyTorch backward pass\n",
    "for p in parameters:\n",
    "    p.grad = None\n",
    "for t in [\n",
    "    logprobs,\n",
    "    probs,\n",
    "    counts,\n",
    "    counts_sum,\n",
    "    counts_sum_inv,  # afaik there is no cleaner way\n",
    "    norm_logits,\n",
    "    logit_maxes,\n",
    "    logits,\n",
    "    h,\n",
    "    hpreact,\n",
    "    bnraw,\n",
    "    bnVar_inv,\n",
    "    bnVar,\n",
    "    bnDiff2,\n",
    "    bnDiff,\n",
    "    hprebn,\n",
    "    bnMeani,\n",
    "    embcat,\n",
    "    emb,\n",
    "]:\n",
    "    t.retain_grad()\n",
    "loss.backward()\n",
    "loss"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1:  Backprop through the whole thing manually, \n",
    "backpropagating through exactly all of the variables as they are defined in the forward pass above, one by one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logprobs        | exact: True  | approximate: True  | maxdiff: 0.0\n"
     ]
    }
   ],
   "source": [
    "# dlogprobs: calculation of the gradient/derivative of the loss wrt all the elements of the logprobs tensor\n",
    "dlogprobs = torch.zeros_like(logprobs)\n",
    "dlogprobs[range(n), Y_batch] = -1.0 / n\n",
    "cmp(\"logprobs\", dlogprobs, logprobs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "probs           | exact: True  | approximate: True  | maxdiff: 0.0\n"
     ]
    }
   ],
   "source": [
    "# the local derivate of log * the derivate loss wrt to its output (dlogprobs)\n",
    "# d/d(x) of log(x) = 1/x\n",
    "dprobs = (1.0 / probs) * dlogprobs\n",
    "cmp(\"probs\", dprobs, probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counts_sum_inv  | exact: True  | approximate: True  | maxdiff: 0.0\n"
     ]
    }
   ],
   "source": [
    "# probs = counts * counts_sum_inv\n",
    "# the local derivative of counts (dp/dcsi) * the derivate loss wrt to probs\n",
    "dcounts_sum_inv = (counts * dprobs).sum(1, keepdim=True)\n",
    "cmp(\"Counts_sum_inv\", dcounts_sum_inv, counts_sum_inv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the local derivative of counts_sum_inv (dp/dc) * the derivate loss wrt to probs\n",
    "dcounts = counts_sum_inv * dprobs\n",
    "# cmp(\"Counts\", dcounts, counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counts_sum      | exact: True  | approximate: True  | maxdiff: 0.0\n"
     ]
    }
   ],
   "source": [
    "# d/dx(x**-1) = -1/x**2\n",
    "dcounts_sum = (-(counts_sum**-2)) * dcounts_sum_inv\n",
    "cmp(\"Counts_sum\", dcounts_sum, counts_sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counts          | exact: True  | approximate: True  | maxdiff: 0.0\n"
     ]
    }
   ],
   "source": [
    "# second branch of dcounts\n",
    "dcounts += torch.ones_like(counts) * dcounts_sum\n",
    "cmp(\"Counts\", dcounts, counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "norm_logits     | exact: True  | approximate: True  | maxdiff: 0.0\n"
     ]
    }
   ],
   "source": [
    "# the local derivate of exp * the derivate loss wrt to its output (counts)\n",
    "# d(a^x)/dx = a^x * ln a\n",
    "dnorm_logits = counts * dcounts\n",
    "cmp(\"norm_logits\", dnorm_logits, norm_logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logit_maxes     | exact: True  | approximate: True  | maxdiff: 0.0\n"
     ]
    }
   ],
   "source": [
    "# norm_logits = logits - logit_maxes\n",
    "dlogits = dnorm_logits.clone()\n",
    "dlogits_maxes = (-dnorm_logits).sum(1, keepdim=True)\n",
    "cmp(\"logit_maxes\", dlogits_maxes, logit_maxes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fb703863ca0>"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# an array of where the maximum values came from for logits\n",
    "plt.imshow(Func.one_hot(logits.max(1).indices, num_classes=logits.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logits          | exact: True  | approximate: True  | maxdiff: 0.0\n"
     ]
    }
   ],
   "source": [
    "dlogits += (\n",
    "    Func.one_hot(logits.max(1).indices, num_classes=logits.shape[1]) * dlogits_maxes\n",
    ")\n",
    "cmp(\"logits\", dlogits, logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "h               | exact: True  | approximate: True  | maxdiff: 0.0\n"
     ]
    }
   ],
   "source": [
    "# logits = h @ W2 + b2\n",
    "# dL/dh = dL/dlogits @ w2-transpose\n",
    "dh = dlogits @ W2.T\n",
    "cmp(\"h\", dh, h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W2              | exact: True  | approximate: True  | maxdiff: 0.0\n"
     ]
    }
   ],
   "source": [
    "# dL/dw2 = h-transpose @ dL/dlogits\n",
    "dW2 = h.T @ dlogits\n",
    "cmp(\"W2\", dW2, W2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b2              | exact: True  | approximate: True  | maxdiff: 0.0\n"
     ]
    }
   ],
   "source": [
    "# dL/db2 = dL/dLogits.sum(0)\n",
    "db2 = dlogits.sum(0)\n",
    "cmp(\"b2\", db2, b2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hpreact         | exact: True  | approximate: True  | maxdiff: 0.0\n"
     ]
    }
   ],
   "source": [
    "# h = torch.tanh(hpreact)\n",
    "# derivative of tanh = 1 - a**2, where a is the output of the tanh\n",
    "dhpreact = (1.0 - h**2) * dh\n",
    "cmp(\"hpreact\", dhpreact, hpreact)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bngain          | exact: True  | approximate: True  | maxdiff: 0.0\n"
     ]
    }
   ],
   "source": [
    "# hpreact = bnGain * bnraw + bnBias\n",
    "dbnGain = (bnraw * dhpreact).sum(0, keepdim=True)\n",
    "\n",
    "cmp(\"bngain\", dbnGain, bnGain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bnraw           | exact: True  | approximate: True  | maxdiff: 0.0\n"
     ]
    }
   ],
   "source": [
    "dbnraw = bnGain * dhpreact\n",
    "cmp(\"bnraw\", dbnraw, bnraw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bnbias          | exact: True  | approximate: True  | maxdiff: 0.0\n"
     ]
    }
   ],
   "source": [
    "dbnBias = (dhpreact).sum(0, keepdim=True)\n",
    "cmp(\"bnbias\", dbnBias, bnBias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bnDiff          | exact: False | approximate: False | maxdiff: 0.0012436023680493236\n"
     ]
    }
   ],
   "source": [
    "# bnraw = bnDiff * bnVar_inv\n",
    "dbnDiff = bnVar_inv * dbnraw\n",
    "cmp(\"bnDiff\", dbnDiff, bnDiff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bnvar_inv       | exact: True  | approximate: True  | maxdiff: 0.0\n"
     ]
    }
   ],
   "source": [
    "# bnraw = bnDiff * bnVar_inv\n",
    "dbnVar_inv = (bnDiff * dbnraw).sum(0, keepdim=True)\n",
    "cmp(\"bnvar_inv\", dbnVar_inv, bnVar_inv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bnvar           | exact: True  | approximate: True  | maxdiff: 0.0\n"
     ]
    }
   ],
   "source": [
    "# d(x^n)/dx = nx^(n-1)\n",
    "# bnVar_inv = (bnVar + 1e-5) ** -0.5\n",
    "dbnVar = (-0.5 * ((bnVar + 1e-5) ** -1.5)) * dbnVar_inv\n",
    "cmp(\"bnvar\", dbnVar, bnVar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bnDiff2         | exact: True  | approximate: True  | maxdiff: 0.0\n"
     ]
    }
   ],
   "source": [
    "# bnVar = (1 / (n - 1) * (bnDiff2).sum(0, keepdim=True))\n",
    "dbnDiff2 = (1.0 / (n - 1)) * torch.ones_like(bnDiff2) * dbnVar\n",
    "cmp(\"bnDiff2\", dbnDiff2, bnDiff2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([32, 200]), torch.Size([32, 200]))"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bnDiff2.shape, bnDiff.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bnDiff          | exact: True  | approximate: True  | maxdiff: 0.0\n"
     ]
    }
   ],
   "source": [
    "# bnDiff2 = bnDiff**2\n",
    "dbnDiff += (2 * bnDiff) * dbnDiff2\n",
    "cmp(\"bnDiff\", dbnDiff, bnDiff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bnmeani         | exact: True  | approximate: True  | maxdiff: 0.0\n"
     ]
    }
   ],
   "source": [
    "# bnDiff = hprebn - bnMeani\n",
    "dbnMeani = (-dbnDiff).sum(0)\n",
    "cmp(\"bnmeani\", dbnMeani, bnMeani)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hprebn          | exact: False | approximate: False | maxdiff: 0.0015779449604451656\n"
     ]
    }
   ],
   "source": [
    "dhprebn = dbnDiff.clone()\n",
    "cmp(\"hprebn\", dhprebn, hprebn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hprebn          | exact: True  | approximate: True  | maxdiff: 0.0\n"
     ]
    }
   ],
   "source": [
    "# bnMeani = 1 / n * hprebn.sum(0, keepdim=True)\n",
    "dhprebn += ((1 / n) * torch.ones_like(hprebn)) * dbnMeani\n",
    "cmp(\"hprebn\", dhprebn, hprebn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "embcat          | exact: True  | approximate: True  | maxdiff: 0.0\n"
     ]
    }
   ],
   "source": [
    "# hprebn = embcat @ W1 + b1\n",
    "dembcat = dhprebn @ W1.T\n",
    "cmp(\"embcat\", dembcat, embcat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W1              | exact: True  | approximate: True  | maxdiff: 0.0\n"
     ]
    }
   ],
   "source": [
    "dW1 = embcat.T @ dhprebn\n",
    "cmp(\"W1\", dW1, W1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b1              | exact: True  | approximate: True  | maxdiff: 0.0\n"
     ]
    }
   ],
   "source": [
    "db1 = dhprebn.sum(0)\n",
    "cmp(\"b1\", db1, b1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "emb             | exact: True  | approximate: True  | maxdiff: 0.0\n"
     ]
    }
   ],
   "source": [
    "# embcat = emb.view(emb.shape[0], -1)\n",
    "demb = dembcat.view(emb.shape)\n",
    "cmp(\"emb\", demb, emb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C               | exact: True  | approximate: True  | maxdiff: 0.0\n"
     ]
    }
   ],
   "source": [
    "# emb = C[X_batch]\n",
    "dC = torch.zeros_like(C)\n",
    "for k in range(X_batch.shape[0]):\n",
    "    for j in range(X_batch.shape[1]):\n",
    "        ix = X_batch[k, j]\n",
    "        dC[ix] += demb[k, j]\n",
    "cmp(\"C\", dC, C)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Combined Results**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logprobs        | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "probs           | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "counts_sum_inv  | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "counts_sum      | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "counts          | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "norm_logits     | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "logit_maxes     | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "logits          | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "h               | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "W2              | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "b2              | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "hpreact         | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "bnGain          | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "bnbias          | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "bnraw           | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "bnVar_inv       | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "bnVar           | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "bnDiff2         | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "bnDiff          | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "bnmeani         | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "hprebn          | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "embcat          | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "W1              | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "b1              | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "emb             | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "C               | exact: True  | approximate: True  | maxdiff: 0.0\n"
     ]
    }
   ],
   "source": [
    "cmp(\"logprobs\", dlogprobs, logprobs)\n",
    "cmp(\"probs\", dprobs, probs)\n",
    "cmp(\"counts_sum_inv\", dcounts_sum_inv, counts_sum_inv)\n",
    "cmp(\"counts_sum\", dcounts_sum, counts_sum)\n",
    "cmp(\"counts\", dcounts, counts)\n",
    "cmp(\"norm_logits\", dnorm_logits, norm_logits)\n",
    "cmp(\"logit_maxes\", dlogits_maxes, logit_maxes)\n",
    "cmp(\"logits\", dlogits, logits)\n",
    "cmp(\"h\", dh, h)\n",
    "cmp(\"W2\", dW2, W2)\n",
    "cmp(\"b2\", db2, b2)\n",
    "cmp(\"hpreact\", dhpreact, hpreact)\n",
    "cmp(\"bnGain\", dbnGain, bnGain)\n",
    "cmp(\"bnbias\", dbnBias, bnBias)\n",
    "cmp(\"bnraw\", dbnraw, bnraw)\n",
    "cmp(\"bnVar_inv\", dbnVar_inv, bnVar_inv)\n",
    "cmp(\"bnVar\", dbnVar, bnVar)\n",
    "cmp(\"bnDiff2\", dbnDiff2, bnDiff2)\n",
    "cmp(\"bnDiff\", dbnDiff, bnDiff)\n",
    "cmp(\"bnmeani\", dbnMeani, bnMeani)\n",
    "cmp(\"hprebn\", dhprebn, hprebn)\n",
    "cmp(\"embcat\", dembcat, embcat)\n",
    "cmp(\"W1\", dW1, W1)\n",
    "cmp(\"b1\", db1, b1)\n",
    "cmp(\"emb\", demb, emb)\n",
    "cmp(\"C\", dC, C)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "fd8fde6f83dada9276d12fdb71d773558994168ed1b3bea457b8db38c02aa2e1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
